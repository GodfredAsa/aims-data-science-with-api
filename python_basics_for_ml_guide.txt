================================================================================
  PYTHON BASICS FOR MACHINE LEARNING — A PRACTICAL GUIDE
================================================================================

This guide covers Python fundamentals you need before diving into machine 
learning. Each section builds toward using libraries like NumPy, pandas, 
and scikit-learn effectively.


--------------------------------------------------------------------------------
PART 1: CORE PYTHON
--------------------------------------------------------------------------------

1.1 VARIABLES AND DATA TYPES
----------------------------
• Variables hold data. No type declaration needed:
    x = 5
    name = "hello"
    price = 19.99

• Essential types for ML:
  - int, float   → numbers (features, targets, indices)
  - str          → labels, file paths, column names
  - bool         → flags, masks, conditions
  - None         → missing or unset values

• Check type: type(x)
• Convert: int(), float(), str(), bool()


1.2 LISTS — YOUR FIRST "ARRAY"
------------------------------
• Ordered, mutable sequence. Very common in ML for small data or indices.

    scores = [85, 90, 78, 92]
    mixed = [1, "two", 3.0, True]

• Indexing: scores[0] → 85, scores[-1] → 92 (last)
• Slicing: scores[1:3] → [90, 78] (start:stop, stop excluded)
• Append: scores.append(88)
• Length: len(scores)

• List comprehensions (used everywhere in ML code):
    squared = [x**2 for x in scores]
    evens = [x for x in range(10) if x % 2 == 0]


1.3 DICTIONARIES — KEY–VALUE PAIRS
----------------------------------
• Map keys to values. Great for configs, hyperparameters, metadata.

    params = {"learning_rate": 0.01, "epochs": 100}
    params["batch_size"] = 32
    value = params.get("lr", 0.001)  # default if key missing


1.4 CONTROL FLOW
----------------
• if / elif / else:
    if score > 0.9:
        print("Good model")
    elif score > 0.7:
        print("Okay")
    else:
        print("Retrain")

• for loops (over lists, ranges, dicts):
    for i in range(5):
        print(i)
    for key, value in params.items():
        print(key, value)

• while: use when you don’t know iterations in advance (less common in ML).


1.5 FUNCTIONS
-------------
• Reusable blocks. ML code is full of small functions (preprocessing, metrics).

    def normalize(x, min_val=0, max_val=1):
        return (x - min_val) / (max_val - min_val)

• Return multiple values (e.g. train/test split logic):
    def split_data(data, ratio=0.8):
        n = int(len(data) * ratio)
        return data[:n], data[n:]


1.6 MODULES AND IMPORTS
-----------------------
• Organize code and use libraries:
    import math
    from math import sqrt
    import numpy as np   # convention: "np" for NumPy

• You will constantly use: import numpy as np, import pandas as pd


--------------------------------------------------------------------------------
PART 2: NUMPY — FOUNDATION FOR ML
--------------------------------------------------------------------------------
NumPy gives you fast arrays and math. Almost every ML library uses it.

2.1 ARRAYS
----------
• Create from list:
    import numpy as np
    arr = np.array([1, 2, 3, 4, 5])

• Shape and dtype:
    arr.shape   # (5,)
    arr.dtype   # int64 or float64

• 2D arrays (like a table of features):
    matrix = np.array([[1, 2], [3, 4], [5, 6]])
    matrix.shape  # (3, 2) — 3 rows, 2 columns

• Useful constructors:
    np.zeros((3, 4))
    np.ones((2, 2))
    np.arange(0, 10, 2)   # 0, 2, 4, 6, 8
    np.linspace(0, 1, 5)  # 5 values from 0 to 1


2.2 INDEXING AND SLICING
------------------------
• Same idea as lists, but for multiple dimensions:
    matrix[1, 0]      # row 1, col 0
    matrix[:, 0]      # first column (all rows)
    matrix[1:3, :]    # rows 1 and 2, all columns

• Boolean indexing (filtering — very important in ML):
    arr = np.array([1, 2, 3, 4, 5])
    arr[arr > 3]      # array([4, 5])


2.3 OPERATIONS
--------------
• Element-wise (no loops needed):
    a + b, a * b, a ** 2
    np.sqrt(a), np.exp(a), np.log(a)

• Aggregations (reduce dimensions):
    arr.sum(), arr.mean(), arr.std(), arr.min(), arr.max()
    matrix.sum(axis=0)   # sum down columns
    matrix.mean(axis=1)  # mean across rows

• Linear algebra (for ML math):
    np.dot(a, b)   # dot product / matrix multiply
    A @ B          # matrix multiplication (Python 3.5+)


2.4 BROADCASTING
----------------
• NumPy expands dimensions automatically so shapes match:
    matrix + np.array([10, 20])  # add 10 to col 0, 20 to col 1

• Rules: dimensions are compared from the right; missing dimensions are "1".
  Understanding this saves a lot of loops in ML code.


--------------------------------------------------------------------------------
PART 3: WORKING WITH DATA (PANDAS BASICS)
--------------------------------------------------------------------------------
pandas is for tables (DataFrames). You load CSVs, filter rows, select columns.

3.1 SERIES AND DATAFRAME
------------------------
    import pandas as pd
    df = pd.read_csv("data.csv")

• Inspect:
    df.head()
    df.info()
    df.describe()
    df.shape

• Columns: df.columns
• Select column: df["column_name"] or df.column_name
• Select rows: df[df["age"] > 30]
• Multiple columns: df[["name", "score"]]


3.2 MISSING VALUES
------------------
• Detect: df.isna(), df.isna().sum()
• Drop: df.dropna()
• Fill: df.fillna(0) or df.fillna(df.mean())


3.3 NUMPY AND PANDAS TOGETHER
-----------------------------
• DataFrame → NumPy (for scikit-learn, etc.):
    X = df[["feature1", "feature2"]].values
    y = df["target"].values

• NumPy → DataFrame (for saving or inspection):
    pd.DataFrame(X, columns=["f1", "f2"])


--------------------------------------------------------------------------------
PART 4: GETTING READY FOR ML
--------------------------------------------------------------------------------

4.1 TYPICAL WORKFLOW
--------------------
1. Load data (pandas: read_csv, read_excel).
2. Explore (head, describe, value_counts, simple plots).
3. Clean (handle missing values, outliers, wrong types).
4. Prepare features (select columns, encode categories, scale).
5. Convert to NumPy (or keep DataFrame and use column names).
6. Split: train / validation / test (e.g. 80% / 10% / 10%).
7. Train a model (e.g. from scikit-learn).
8. Evaluate (accuracy, MSE, etc.) and iterate.

4.2 CONCEPTS TO COMFORT WITH
----------------------------
• Features (X) vs target (y).
• Training set vs test set (never train on test).
• Numerical vs categorical variables (encoding).
• Scaling (e.g. StandardScaler) when algorithms are sensitive to scale.

4.3 NEXT STEPS
--------------
• Practice: small datasets, linear regression, classification (e.g. k-NN, logistic regression).
• Learn: train_test_split, fit/predict, basic metrics (accuracy, mean_squared_error).
• Then: more models, cross-validation, pipelines, and deeper ML topics.

================================================================================
  QUICK REFERENCE
================================================================================
  List comp:     [x*2 for x in lst if x > 0]
  NumPy array:   np.array(lst), arr.shape, arr.mean()
  Pandas:        pd.read_csv(), df["col"], df.values
  ML flow:       Load → Explore → Clean → Features → Split → Train → Evaluate
================================================================================

End of guide. Good luck with your machine learning journey!



